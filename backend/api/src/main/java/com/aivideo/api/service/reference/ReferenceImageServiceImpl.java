package com.aivideo.api.service.reference;

import com.aivideo.common.exception.ApiException;
import com.aivideo.common.exception.ErrorCode;
import com.aivideo.api.service.storage.StorageService;
import com.aivideo.api.service.CreatorConfigService;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.http.*;
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.io.InputStream;
import java.util.*;

/**
 * v2.9.84: ì°¸ì¡° ì´ë¯¸ì§€ ì„œë¹„ìŠ¤ êµ¬í˜„ì²´
 * v2.9.149: í‹°ì–´ë³„ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë¸ ì‚¬ìš© (ai_model í…Œì´ë¸” ê¸°ë°˜)
 * v2.9.150: ë¶„ì„ í”„ë¡¬í”„íŠ¸ DB ê¸°ë°˜ ê´€ë¦¬ (creator_prompts.reference_image_analysis)
 *
 * ë‹´ë‹¹ ê¸°ëŠ¥:
 * 1. ì´ë¯¸ì§€ ê²€ì¦ (íƒ€ì…, í¬ê¸°)
 * 2. S3 ì—…ë¡œë“œ (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)
 * 3. Gemini ë©€í‹°ëª¨ë‹¬ ë¶„ì„ (ìºë¦­í„°/ìŠ¤íƒ€ì¼ ì¶”ì¶œ)
 */
@Slf4j
@Service
@RequiredArgsConstructor
public class ReferenceImageServiceImpl implements ReferenceImageService {

    private final StorageService storageService;
    private final RestTemplate restTemplate;
    private final ObjectMapper objectMapper;
    private final CreatorConfigService creatorConfigService;  // v2.9.149: í‹°ì–´ë³„ ëª¨ë¸ ì¡°íšŒ

    // í—ˆìš© MIME íƒ€ì…
    private static final Set<String> ALLOWED_MIME_TYPES = Set.of(
            "image/jpeg", "image/png", "image/webp", "image/gif"
    );

    // ìµœëŒ€ íŒŒì¼ í¬ê¸° (10MB)
    private static final long MAX_FILE_SIZE = 10 * 1024 * 1024;

    // v2.9.149: Gemini API URL í…œí”Œë¦¿ (í‹°ì–´ë³„ ëª¨ë¸ ë™ì  ì ìš©)
    private static final String GEMINI_API_URL_TEMPLATE =
            "https://generativelanguage.googleapis.com/v1beta/models/%s:generateContent";

    @Override
    public void validateImage(MultipartFile image) {
        if (image == null || image.isEmpty()) {
            throw new ApiException(ErrorCode.INVALID_REQUEST, "ì´ë¯¸ì§€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
        }

        String contentType = image.getContentType();
        if (contentType == null || !ALLOWED_MIME_TYPES.contains(contentType.toLowerCase())) {
            throw new ApiException(ErrorCode.INVALID_REQUEST,
                    "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤. (JPEG, PNG, WebP, GIF ì§€ì›)");
        }

        if (image.getSize() > MAX_FILE_SIZE) {
            throw new ApiException(ErrorCode.INVALID_REQUEST,
                    "ì´ë¯¸ì§€ í¬ê¸°ëŠ” 10MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        }

        log.info("[ReferenceImage] Validation passed - type: {}, size: {} bytes",
                contentType, image.getSize());
    }

    @Override
    public String uploadImage(Long chatId, MultipartFile image) {
        validateImage(image);

        // ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
        String originalFilename = image.getOriginalFilename();
        String safeFilename = sanitizeFilename(originalFilename);

        // v2.9.89: S3 key ìƒì„±: content/{chatId}/references/{timestamp}_{filename}
        String key = String.format("content/%d/references/%d_%s",
                chatId, System.currentTimeMillis(), safeFilename);

        try (InputStream inputStream = image.getInputStream()) {
            storageService.upload(key, inputStream, image.getContentType(), image.getSize());
            log.info("[ReferenceImage] v2.9.89 Uploaded to S3 - chatId: {}, key: {}", chatId, key);
            return key;
        } catch (IOException e) {
            log.error("[ReferenceImage] Upload failed - chatId: {}", chatId, e);
            throw new ApiException(ErrorCode.INTERNAL_SERVER_ERROR,
                    "ì°¸ì¡° ì´ë¯¸ì§€ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: " + e.getMessage());
        }
    }

    @Override
    public String analyzeImage(String apiKey, byte[] imageBytes, String mimeType, String userPrompt, Long creatorId) {
        log.info("[ReferenceImage] Starting analysis - size: {} bytes, mimeType: {}, creatorId: {}",
                imageBytes.length, mimeType, creatorId);

        String base64Image = encodeToBase64(imageBytes);

        // DBì—ì„œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ, ì—†ìœ¼ë©´ í´ë°± ì‚¬ìš©
        String analysisPrompt;
        String dbPrompt = creatorConfigService.buildReferenceImageAnalysisPrompt(creatorId, userPrompt);
        if (dbPrompt != null) {
            analysisPrompt = dbPrompt;
            log.info("[ReferenceImage] Using DB analysis prompt for creatorId: {}", creatorId);
        } else if (isReviewCreator(creatorId)) {
            analysisPrompt = buildProductAnalysisPromptFallback(userPrompt);
            log.info("[ReferenceImage] Using PRODUCT analysis prompt fallback for REVIEW creator");
        } else {
            analysisPrompt = buildCharacterAnalysisPrompt(userPrompt);
            log.info("[ReferenceImage] Using CHARACTER analysis prompt for genre: {}", creatorId);
        }

        // Gemini API ìš”ì²­ êµ¬ì„± (ë©€í‹°ëª¨ë‹¬)
        Map<String, Object> requestBody = buildGeminiRequest(analysisPrompt, base64Image, mimeType);

        // v2.9.149: í‹°ì–´ë³„ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë¸ ì¡°íšŒ
        String scenarioModel = creatorConfigService.getScenarioModel(creatorId);
        String apiUrl = String.format(GEMINI_API_URL_TEMPLATE, scenarioModel) + "?key=" + apiKey;
        log.info("[ReferenceImage] v2.9.149 Using scenario model: {} for creatorId: {}", scenarioModel, creatorId);

        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);

        try {
            String requestJson = objectMapper.writeValueAsString(requestBody);
            HttpEntity<String> entity = new HttpEntity<>(requestJson, headers);

            ResponseEntity<String> response = restTemplate.exchange(
                    apiUrl,
                    HttpMethod.POST,
                    entity,
                    String.class
            );

            if (response.getStatusCode() == HttpStatus.OK && response.getBody() != null) {
                String analysisResult = parseGeminiResponse(response.getBody());
                // v2.9.149: í”„ë¡¬í”„íŠ¸ì—ì„œ ë¸Œëœë“œëª… ìš”ì²­ì„ ì œê±°í–ˆìœ¼ë¯€ë¡œ sanitize ë¶ˆí•„ìš”
                log.info("[ReferenceImage] v2.9.149 Analysis completed - result length: {} chars",
                        analysisResult.length());
                return analysisResult;
            }

            log.warn("[ReferenceImage] Analysis returned non-OK status: {}", response.getStatusCode());
            return "{}";

        } catch (Exception e) {
            log.error("[ReferenceImage] Analysis failed: {}", e.getMessage(), e);
            // ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë¹ˆ JSON ë°˜í™˜ (ì½˜í…ì¸  ìƒì„±ì€ ê³„ì† ì§„í–‰)
            return "{}";
        }
    }

    @Override
    public String encodeToBase64(byte[] imageBytes) {
        return Base64.getEncoder().encodeToString(imageBytes);
    }

    @Override
    public byte[] downloadImage(String s3Key) {
        if (s3Key == null || s3Key.isEmpty()) {
            throw new ApiException(ErrorCode.INVALID_REQUEST, "S3 keyê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
        }
        return storageService.download(s3Key);
    }

    @Override
    public String generatePresignedUrl(String s3Key) {
        if (s3Key == null || s3Key.isEmpty()) {
            return null;
        }
        return storageService.generatePresignedUrl(s3Key);
    }

    /**
     * íŒŒì¼ëª… ì•ˆì „ ì²˜ë¦¬ (ê²½ë¡œ ì¡°ì‘ ë°©ì§€)
     */
    private String sanitizeFilename(String filename) {
        if (filename == null || filename.isEmpty()) {
            return "image";
        }
        // ê²½ë¡œ êµ¬ë¶„ì ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì œê±°
        return filename.replaceAll("[^a-zA-Z0-9._-]", "_");
    }

    /**
     * v2.9.85: ìºë¦­í„°/ìŠ¤íƒ€ì¼ ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ADULT, FINANCE ë“± ì¼ë°˜ ì¥ë¥´ìš©)
     */
    private String buildCharacterAnalysisPrompt(String userPrompt) {
        StringBuilder prompt = new StringBuilder();
        prompt.append("Analyze this reference image for AI video content generation.\n\n");

        if (userPrompt != null && !userPrompt.isEmpty()) {
            prompt.append("User's content idea: ").append(userPrompt).append("\n\n");
        }

        prompt.append("""
                Extract and describe in English for AI image/video generation:

                1. CHARACTER: If a person is visible, describe in detail:
                   - Gender, estimated age, ethnicity
                   - Hair (color, style, length)
                   - Eyes (color, shape)
                   - Face shape, skin tone
                   - Body type, height impression
                   - Any distinctive features

                2. STYLE: Visual and artistic style:
                   - Photography style (cinematic, portrait, fashion, etc.)
                   - Lighting (natural, studio, dramatic, soft, etc.)
                   - Color grading and tones
                   - Overall aesthetic

                3. OUTFIT: If clothing is visible:
                   - Clothing type and style
                   - Colors and patterns
                   - Accessories

                4. SETTING: Background and environment:
                   - Location type (indoor/outdoor, specific setting)
                   - Atmosphere and mood
                   - Key visual elements

                5. COLOR_PALETTE: Main colors in the image (list 3-5 colors)

                6. MOOD: Overall mood and atmosphere (1-2 words)

                Output as valid JSON only (no markdown, no explanation):
                {
                  "characterDescription": "...",
                  "styleDescription": "...",
                  "outfitDescription": "...",
                  "settingDescription": "...",
                  "colorPalette": "...",
                  "moodAtmosphere": "..."
                }
                """);

        return prompt.toString();
    }

    /**
     * v2.9.150: ìƒí’ˆ ë¶„ì„ í”„ë¡¬í”„íŠ¸ í´ë°± (DBì— í”„ë¡¬í”„íŠ¸ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)
     *
     * ğŸš¨ CRITICAL: ì´ í”„ë¡¬í”„íŠ¸ëŠ” ìƒí’ˆ ë¦¬ë·° ì½˜í…ì¸  ìƒì„±ì˜ í•µì‹¬ì…ë‹ˆë‹¤.
     * ì°¸ì¡° ì´ë¯¸ì§€ì—ì„œ ìƒí’ˆ ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ ë™ì¼í•œ ìƒí’ˆì´ ì½˜í…ì¸ ì— ë“±ì¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.
     *
     * v2.9.149: ë” ë””í…Œì¼í•œ ì‹œê°ì  ë¶„ì„ ì¶”ê°€ (ì˜ìƒ ì¬í˜„ì„ ìœ„í•œ ìƒì„¸ ì •ë³´)
     * v2.9.150: DB í”„ë¡¬í”„íŠ¸ ìš°ì„ , ì´ ë©”ì„œë“œëŠ” í´ë°±ìœ¼ë¡œë§Œ ì‚¬ìš©
     */
    private String buildProductAnalysisPromptFallback(String userPrompt) {
        StringBuilder prompt = new StringBuilder();
        prompt.append("""
                ğŸ¬ ULTRA-DETAILED PRODUCT ANALYSIS FOR VIDEO GENERATION

                You are analyzing a PRODUCT IMAGE for AI video generation.
                Your analysis will be used DIRECTLY in video prompts, so be EXTREMELY DETAILED.
                The video must show the EXACT SAME product with identical visual characteristics.

                âš ï¸ CRITICAL: NO BRAND NAMES, NO MODEL NUMBERS - use only visual descriptions!

                """);

        if (userPrompt != null && !userPrompt.isEmpty()) {
            prompt.append("User's product description: ").append(userPrompt).append("\n\n");
        }

        prompt.append("""
                EXTRACT EVERY VISUAL DETAIL:

                1. PRODUCT_TYPE (NO brands/models):
                   - Generic category: "flagship smartphone", "wireless earbuds", "skincare serum"
                   - Key function: "with stylus pen support", "noise-canceling", "anti-aging"

                2. EXACT_SHAPE:
                   - 3D form: rectangular slab, cylindrical tube, spherical jar, teardrop bottle
                   - Proportions: height-to-width ratio, thickness
                   - Edge style: rounded corners, sharp edges, beveled, curved

                3. DIMENSIONS_AND_SCALE:
                   - Relative size: palm-sized, finger-tip sized, hand-length
                   - Thickness: ultra-thin, slim, chunky, bulky
                   - Weight impression: lightweight, substantial, heavy-looking

                4. MATERIAL_AND_TEXTURE:
                   - Surface material: brushed aluminum, frosted glass, smooth plastic, leather
                   - Texture feel: silky matte, mirror glossy, soft-touch, textured grip
                   - Transparency: opaque, translucent, transparent, tinted

                5. COLOR_PALETTE (be VERY specific):
                   - Primary: exact shade (not "black" but "jet black with subtle blue undertone")
                   - Secondary: accent colors and where they appear
                   - Finish: metallic shimmer, pearlescent, holographic, matte, glossy
                   - Gradients: if colors blend or transition

                6. DISTINCTIVE_FEATURES:
                   - Buttons/controls: location, shape, color
                   - Ports/openings: position, size
                   - Display/screen: size relative to body, bezel thickness
                   - Decorative elements: lines, patterns, embossing

                7. LIGHTING_IN_IMAGE:
                   - Light direction: from top-left, front, diffused
                   - Highlights: where light reflects brightest
                   - Shadows: shadow direction and softness
                   - Overall mood: bright and clean, dramatic, soft and warm

                8. CAMERA_ANGLE:
                   - Perspective: straight-on, 45-degree angle, top-down, low angle
                   - Distance: close-up macro, medium shot, full product view
                   - Focus: what's sharp vs blurred

                9. BACKGROUND_AND_SETTING:
                   - Background color/type: white studio, marble surface, wooden desk
                   - Props if any: plants, accessories, hands
                   - Environment feel: minimalist, lifestyle, professional

                10. COMPOSITION:
                    - Product position: centered, rule-of-thirds, floating
                    - Negative space: how much empty space around product
                    - If hands visible: how they hold/interact with product

                Output as valid JSON only (no markdown):
                {
                  "productType": "Generic type with key function (NO brand names)",
                  "exactShape": "3D form, proportions, edge style in detail",
                  "dimensions": "Relative size, thickness, weight impression",
                  "material": "Surface material, texture feel, transparency level",
                  "colors": "Primary: [exact shade], Secondary: [accents], Finish: [type]",
                  "distinctiveFeatures": "Buttons, ports, display, decorative elements",
                  "lighting": "Light direction, highlights, shadows, mood",
                  "cameraAngle": "Perspective, distance, focus area",
                  "background": "Background type, props, environment feel",
                  "composition": "Product position, negative space, hand interaction if any",
                  "videoPromptSuggestion": "One-paragraph description combining all above for video generation"
                }

                ğŸš¨ RULES:
                - NO brand names (Samsung, Apple, Sony, etc.)
                - NO model numbers (S26, iPhone 16, etc.)
                - Be EXTREMELY specific about visual details
                - The "videoPromptSuggestion" should be a ready-to-use prompt for video generation
                """);

        return prompt.toString();
    }

    /**
     * Gemini API ë©€í‹°ëª¨ë‹¬ ìš”ì²­ êµ¬ì„±
     */
    private Map<String, Object> buildGeminiRequest(String prompt, String base64Image, String mimeType) {
        Map<String, Object> requestBody = new HashMap<>();

        // contents - í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€
        List<Map<String, Object>> contents = new ArrayList<>();
        Map<String, Object> content = new HashMap<>();

        // parts ë°°ì—´: í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€
        List<Map<String, Object>> parts = new ArrayList<>();

        // í…ìŠ¤íŠ¸ íŒŒíŠ¸
        parts.add(Map.of("text", prompt));

        // ì´ë¯¸ì§€ íŒŒíŠ¸ (inlineData)
        parts.add(Map.of("inlineData", Map.of(
                "mimeType", mimeType,
                "data", base64Image
        )));

        content.put("parts", parts);
        contents.add(content);
        requestBody.put("contents", contents);

        // generationConfig
        Map<String, Object> generationConfig = new HashMap<>();
        generationConfig.put("responseMimeType", "application/json");
        generationConfig.put("temperature", 0.4);
        requestBody.put("generationConfig", generationConfig);

        return requestBody;
    }

    /**
     * Gemini ì‘ë‹µ íŒŒì‹±
     */
    private String parseGeminiResponse(String responseBody) {
        try {
            JsonNode root = objectMapper.readTree(responseBody);
            JsonNode candidates = root.path("candidates");

            if (candidates.isArray() && !candidates.isEmpty()) {
                JsonNode firstCandidate = candidates.get(0);
                JsonNode content = firstCandidate.path("content");
                JsonNode parts = content.path("parts");

                if (parts.isArray() && !parts.isEmpty()) {
                    JsonNode textNode = parts.get(0).path("text");
                    if (!textNode.isMissingNode()) {
                        String text = textNode.asText();
                        // JSON ìœ íš¨ì„± ê²€ì¦
                        objectMapper.readTree(text);
                        return text;
                    }
                }
            }

            log.warn("[ReferenceImage] Could not parse analysis result");
            return "{}";

        } catch (Exception e) {
            log.error("[ReferenceImage] Failed to parse Gemini response: {}", e.getMessage());
            return "{}";
        }
    }

    /**
     * Check if the creator is a REVIEW-type creator by creatorCode.
     */
    private boolean isReviewCreator(Long creatorId) {
        if (creatorId == null) return false;
        try {
            return "REVIEW".equals(creatorConfigService.getCreator(creatorId).getCreatorCode());
        } catch (Exception e) {
            return false;
        }
    }
}
